<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Jiacheng Xie</title>

  <meta name="author" content="Jiacheng Xie">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">

</head>

<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p class="name" style="text-align: center;">
                    Jiacheng Xie
                  </p>
                  <p>
                    I'm a Ph.D student and research assistant at <a href="https://digbio.missouri.edu/">Digital
                      Biology</a> in University of Missouri.
                  </p>
                  <p style="text-align:center">
                    <a href="mailto:jiachengxie@missouri.edu">Email</a> &nbsp;/&nbsp;
                    <a href="data/jiachengxie-CV.pdf">CV</a> &nbsp;/&nbsp;
                    <a href="https://scholar.google.com/citations?user=1vQxsesAAAAJ&hl=zh-CN">Scholar</a> &nbsp;/&nbsp;
                    <a href="https://github.com/orangeshushu">Github</a>
                  </p>
                </td>
                <td style="padding:2.5%;width:37%;max-width:37%">
                  <a href="images/Jiacheng-Xie.jpg"><img
                      style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo"
                      src="images/Jiacheng-Xie.jpg" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:16px;width:100%;vertical-align:middle">
                  <h2>Research</h2>
                  <p>
                    I'm interested in medical imaging analysis, clinical decision support systems, and the application
                    of artificial intelligence in medicine and healthcare. My recent work also explores epidemiological
                    insights derived from social media data. Much of my research focuses on building AI systems that can
                    assist clinical diagnosis, treatment planning, and public health surveillance. Selected projects and
                    publications are <span class="highlight">highlighted</span> below.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>


              <tr onmouseout="bolt3d_stop()" onmouseover="bolt3d_start()" bgcolor="#ffffd0">
                <td style="padding:16px;width:20%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='bolt3d_image'><video width=100% height=100% muted autoplay loop>
                        <source src="images/co" type="video/mp4">
                        Your browser does not support the video tag.

                      </video></div>
                    <img src='images/covlab.png' width="160">
                  </div>
                  <script type="text/javascript">
                    function bolt3d_start() {
                      document.getElementById('bolt3d_image').style.opacity = "1";
                    }

                    function bolt3d_stop() {
                      document.getElementById('bolt3d_image').style.opacity = "0";
                    }
                    bolt3d_stop()
                  </script>
                </td>
                <td style="padding:8px;width:80%;vertical-align:middle">
                  <a href="https://covlab.tech/#/home">
                    <span class="papertitle">Leveraging Large Language Models for Infectious Disease Surveillance—Using
                      a Web Service for Monitoring COVID-19 Patterns From Self-Reporting Tweets: Content Analysis</span>
                  </a>
                  <br>
                  <!-- <a href="#">Jiacheng Xie</a>, -->
                  <!-- <a href="https://jasonyzhang.com">Jason Y. Zhang</a>,
        <a href="https://pratulsrinivasan.github.io">Pratul Srinivasan</a>,
        <a href="https://ruiqigao.github.io">Ruiqi Gao</a>,
        <a href="https://github.com/ArthurBrussee">Arthur Brussee</a>,
        <a href="https://holynski.org">Aleksander Holynski</a>,
        <a href="https://ricardomartinbrualla.com">Ricardo Martin-Brualla</a>, -->
                  <!-- <strong>Jonathan T. Barron</strong>, -->
                  <!-- <a href="https://henzler.github.io">Philipp Henzler</a> -->
                  <br>
                  <em>Journal of Medical Internet Research</em>, 2025
                  <br>
                  <a href="https://covlab.tech/#/home">project page</a>
                  /
                  <a href="https://www.jmir.org/2025/1/e63190">paper</a>
                  <p></p>
                  <p>
                    In this work, we developed a real-time COVID-19 surveillance system based on self-reported cases
                    from Twitter, using large language models to automatically detect infections, symptoms, recoveries,
                    and reinfections. Our system predicted national case trends an average of 7.6 days earlier than
                    official reports and uncovered rare symptoms not listed by the CDC. We deployed these findings
                    through an interactive platform, Covlab, to support public health decision-making and early outbreak
                    detection.
                  </p>
                </td>
              </tr>

              <tr onmouseout="ever_stop()" onmouseover="ever_start()">
                <td style="padding:16px;width:20%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='ever_image'>
                      <img src='images/Digital-tongue-image-analyses-for-health-assessment.jpg' width=100%>
                    </div>
                    <img src='images/Digital-tongue-image-analyses-for-health-assessment.jpg' width=100%>
                  </div>
                  <script type="text/javascript">
                    function ever_start() {
                      document.getElementById('ever_image').style.opacity = "1";
                    }

                    function ever_stop() {
                      document.getElementById('ever_image').style.opacity = "0";
                    }
                    ever_stop()
                  </script>
                </td>
                <td style="padding:8px;width:80%;vertical-align:middle">
                  <a href="https://half-potato.gitlab.io/posts/ever/">
                    <span class="papertitle">Digital tongue image analyses for health assessment
                    </span>
                  </a>
                  <br>
                  <!-- <a href="https://half-potato.gitlab.io/">Alexander Mai</a>, 
				<a href="https://phogzone.com/">Peter Hedman</a>,
				<a href="https://grgkopanas.github.io/">George Kopanas</a>,
        <a href="https://dorverbin.github.io/">Dor Verbin</a>,
        <a href="https://scholar.google.com/citations?user=ozNFrecAAAAJ&hl=en">David Futschik</a>,
        <a href="https://xharlie.github.io/">Qiangeng Xu</a>,
        <a href="https://jacobsschool.ucsd.edu/faculty/profile?id=253">Falko Kuester</a>,
				<strong>Jonathan T. Barron</strong>,
        <a href="https://www.zhangyinda.com/">Yinda Zhang</a> -->
                  <br>
                  <em>Medical Review</em>, 2021
                  <br>
                  <a href="https://itongue.cn/">project page</a>
                  /
                  <a href="https://www.degruyterbrill.com/document/doi/10.1515/mr-2021-0018/html">paper</a>
                  <p></p>
                  <p>
                    In this work, we reviewed recent advances in computerized tongue diagnosis for health assessment,
                    covering key components such as tongue image acquisition devices, region segmentation, feature
                    extraction, and color correction. We compared traditional machine learning and deep learning
                    approaches for tongue-based constitution classification, discussing their respective strengths and
                    limitations. Finally, we highlighted current challenges and outlined future directions for the
                    standardization and intelligent application of digital tongue diagnosis systems.
                  </p>
                </td>
              </tr>


              <tr onmouseout="cat4d_stop()" onmouseover="cat4d_start()">
                <td style="padding:16px;width:20%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='cat4d_image'><video width=100% height=100% muted autoplay loop>
                        <source src="images/tcmladder.png" type="video/mp4">
                        Your browser does not support the video tag.
                      </video></div>
                    <img src='images/tcmladder.png' width="160">
                  </div>
                  <script type="text/javascript">
                    function cat4d_start() {
                      document.getElementById('cat4d_image').style.opacity = "1";
                    }

                    function cat4d_stop() {
                      document.getElementById('cat4d_image').style.opacity = "0";
                    }
                    cat4d_stop()
                  </script>
                </td>
                <td style="padding:8px;width:80%;vertical-align:middle">
                  <a href="https://tcmladder.com/">
                    <span class="papertitle">TCM-Ladder: A Benchmark for Multimodal Question Answering on Traditional
                      Chinese Medicine
                    </span>
                  </a>
                  <br>
                  <!-- <a href="https://www.cs.columbia.edu/~rundi/">Rundi Wu</a>,
				<a href="https://ruiqigao.github.io/">Ruiqi Gao</a>,
				<a href="https://poolio.github.io/">Ben Poole</a>,
				<a href="https://alextrevithick.github.io/">Alex Trevithick</a>,
				<a href="https://www.cs.columbia.edu/~cxz/index.htm/">Changxi Zheng</a>,
				<strong>Jonathan T. Barron</strong>,
				<a href="https://holynski.org/">Aleksander Holynski</a>
        <br> -->
        <br>
        <em>Under Review</em>, 2025 
                  <br>
                  <a href="https://tcmladder.com/">project page</a>
                /
                  <a href="https://arxiv.org/abs/2505.24063">paper</a>
                  <p></p>
                  <p>
                    In this paper, we introduce TCM‑Ladder, the first unified multimodal question-answering benchmark
                    for Traditional Chinese Medicine, consisting of over 52,000 questions across text, image, and video
                    formats. We evaluate both general-purpose and TCM-specific large language models, and propose a new
                    metric, Ladder‑Score, to assess responses based on terminology accuracy and semantic alignment. This
                    benchmark provides a standardized platform to advance the development of multimodal LLMs for TCM.
                  </p>
                </td>
              </tr>
              <tr onmouseout="water_stop()" onmouseover="water_start()" bgcolor="#ffffd0">
                <td style="padding:16px;width:20%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='water_image'>
                      <img src='images/water.png' width=100%>
                    </div>
                    <img src='images/water.png' width=100%>
                  </div>
                  <script type="text/javascript">
                    function water_start() {
                      document.getElementById('water_image').style.opacity = "1";
                    }

                    function water_stop() {
                      document.getElementById('water_image').style.opacity = "0";
                    }
                    water_stop()
                  </script>
                </td>
                <td style="padding:8px;width:80%;vertical-align:middle">
                  <a href="https://half-potato.gitlab.io/posts/ever/">
                    <span class="papertitle">Assessing Environmental Oil Spill Based on Fluorescence Images of Water Samples and Deep Learning
                    </span>
                  </a>
                  <br>
                  <!-- <a href="https://half-potato.gitlab.io/">Alexander Mai</a>, 
				<a href="https://phogzone.com/">Peter Hedman</a>,
				<a href="https://grgkopanas.github.io/">George Kopanas</a>,
        <a href="https://dorverbin.github.io/">Dor Verbin</a>,
        <a href="https://scholar.google.com/citations?user=ozNFrecAAAAJ&hl=en">David Futschik</a>,
        <a href="https://xharlie.github.io/">Qiangeng Xu</a>,
        <a href="https://jacobsschool.ucsd.edu/faculty/profile?id=253">Falko Kuester</a>,
				<strong>Jonathan T. Barron</strong>,
        <a href="https://www.zhangyinda.com/">Yinda Zhang</a> -->
                  <br>
                  <em>Journal of Environmental Informatics</em>, 2023
                  <br>
                  <a href="https://oilix.covlab.tech/">project page</a>
                  /
                  <a href="http://jeionline.org/index.php?journal=mys&page=article&op=viewFile&path[]=202300491&path[]=202300491_pdf">paper</a>
                  <p></p>
                  <p>
                    We developed a portable, plug-and-play device and deep learning model that estimate oil concentration in water using fluorescence images captured by an iPhone. Trained on ~1,300 solvent-extracted samples, the model combines a CNN with a histogram bottleneck block and attention mechanism to extract spectral features from low-contrast images. Our system achieves high accuracy and includes a confidence estimator, offering a practical, near-real-time solution for oil spill responders.
                  </p>
                </td>
              </tr>

              <tr>
                <td style="padding:16px;width:20%;vertical-align:middle">
                  <img src="images/oilix.png" alt="safs_small" width="160" height="160" style="border-style: none">
                </td>
                <td style="padding:8px;width:80%;vertical-align:middle">
                  <a href="https://drive.google.com/file/d/1EZTOO5xezLYcyIFgAzs4KuZFLbTcwTDH/view?usp=sharing">
                    <span class="papertitle">Real-Time Oil Spill Concentration Assessment Through Fluorescence Imaging and Deep Learning</span>
                  </a>
                  <br>
                  <!-- <strong>Jonathan T. Barron</strong>, <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a> -->
                  <br>
                  <em>Under Review</em>, 2025
                  <br>
                  <a href="https://oilix.covlab.tech/">project page</a>
                  /
                  <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5237044">paper</a>
                  <p>We present a real-time oil spill assessment system that integrates fluorescence imaging, deep learning, a mobile app (Oilix), and a data management platform to overcome the limitations of traditional monitoring methods. Using a MobileNetV3-large-based model trained on 1,530 curated fluorescence images from two oil types, our approach achieves high accuracy with an R² of 0.9958 and RMSE of 9.28. Oilix enables rapid, cost-effective, and scalable field assessments, enhancing environmental monitoring and emergency response capabilities.</p>
                </td>
              </tr>

<tr>
                <td style="padding:16px;width:20%;vertical-align:middle">
                  <img src="images/tom.png" alt="safs_small" width="160" height="160" style="border-style: none">
                </td>
                <td style="padding:8px;width:80%;vertical-align:middle">
                  <a href="https://drive.google.com/file/d/1EZTOO5xezLYcyIFgAzs4KuZFLbTcwTDH/view?usp=sharing">
                    <span class="papertitle">TOM: A Universal Tongue Optimization Model for Medical Tongue Image Segmentation</span>
                  </a>
                  <br>
                  <!-- <strong>Jonathan T. Barron</strong>, <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a> -->
                  <br>
                  <em>MIC Conference</em>, 2024
                  <br>
                  <a href="http://toml.itongue.cn/">project page</a>
                  /
                  <a href="https://ieeexplore.ieee.org/abstract/document/10656946">paper</a>
                  <p>In computerized intelligent tongue diagnosis, tongue segmentation is usually used as an input for subsequent downstream tongue diagnosis tasks, and the accuracy of tongue segmentation directly affects the results of tongue diagnosis. Hence, tongue segmentation is of great significance for computerized tongue diagnosis. In this paper, we propose a universal tongue optimization model (TOM) for tongue segmentation. Our method has higher segmentation accuracy and segmentation speed than previous segmentation methods. Even in a complex tongue image dataset with artificially added noise, the TOM method still achieves 97.85% mIoU and saves more than 25% inference time. Moreover, we developed an online tongue segmentation tool (http://www.itongue.cn) based on TOM, which allows doctors to obtain tongue segmentation without coding.</p>
                </td>
              </tr>
              
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px">
                  <br>
                  <p style="text-align:right;font-size:small;">
                    @2025 Jiacheng Xie
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
        </td>
      </tr>
  </table>
</body>

</html>